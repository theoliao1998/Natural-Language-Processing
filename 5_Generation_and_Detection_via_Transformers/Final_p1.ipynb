{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_p1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"751vBEjOdPpb","colab_type":"code","outputId":"f4ab31bb-50ad-4fd1-ea5c-c0b72155afc6","executionInfo":{"status":"ok","timestamp":1587311276348,"user_tz":240,"elapsed":6702,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 4.6MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 21.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 48.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n","\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=4e23f0066b3e4559f4adfc42450ece394ce6cb5571dd3b5e0a07dbaa3725716d\n","  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPuQWhTDdV-0","colab_type":"code","outputId":"d4c0b23e-08b0-4429-b86a-c8335c3d9a7a","executionInfo":{"status":"ok","timestamp":1587311303601,"user_tz":240,"elapsed":32659,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/') "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2R3egpZKeyRe","colab_type":"code","outputId":"92f9d759-e486-4f8d-a279-233766539396","executionInfo":{"status":"ok","timestamp":1587311303602,"user_tz":240,"elapsed":31052,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/gdrive/Shared\\ drives/si630_hw5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/Shared drives/si630_hw5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hKnP-wQfFt2K","colab_type":"code","outputId":"8b2a1089-abbf-4062-bb6d-ab503841581b","executionInfo":{"status":"ok","timestamp":1587311307373,"user_tz":240,"elapsed":31478,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xdKaP9DfJdtW","colab_type":"code","colab":{}},"source":["# default parameters\n","\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qUOKKydJPvm","colab_type":"code","colab":{}},"source":["# tuning on learning rate\n","# learning rate = 5e-4\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output1 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --learning_rate 5e-4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceLIrk9_Jmn5","colab_type":"code","colab":{}},"source":["# learning rate = 5e-3\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output2 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --learning_rate 5e-3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pE3n45e9JpPj","colab_type":"code","colab":{}},"source":["# learning rate = 5e-6\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output3 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --learning_rate 5e-6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlvkNt43IsHE","colab_type":"code","colab":{}},"source":["# tuning on weigth decay\n","# weight decay = 0.1\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --weight_decay=0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm0b3YmtI84K","colab_type":"code","colab":{}},"source":["# weight decay = 0.01\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e2_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --weight_decay=0.01"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DC_n8jjCJCKp","colab_type":"code","colab":{}},"source":["# weight decay = 0.001\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e3_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --weight_decay=0.001"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpiVsloqQivH","colab_type":"code","colab":{}},"source":["# weight decay = 0.0001\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e4_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --weight_decay=0.0001"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWXVrc6yQr8_","colab_type":"code","colab":{}},"source":["# choose weight decay of 0.1 and default learning rate since it performs the best\n","# tune block size = 32\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line_block_32 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --block_size 32 \\\n","    --weight_decay=0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptsEVeu3Q-Sk","colab_type":"code","colab":{}},"source":["# tune block size = 128\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line_block_128 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --block_size 128 \\\n","    --weight_decay=0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W79etapwRB0e","colab_type":"code","colab":{}},"source":["# tune block size = 600\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line_block_600 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --block_size 600 \\\n","    --weight_decay=0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8di5wVmgQn9a","colab_type":"code","colab":{}},"source":["# tune block size = 1024\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line_block_1024 \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=openai-gpt \\\n","    --do_train \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --overwrite_output_dir \\\n","    --save_steps 2000 \\\n","    --line_by_line \\\n","    --block_size 1024 \\\n","    --weight_decay=0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgEXMNG21s8l","colab_type":"code","colab":{}},"source":["# with chosen best model\n","# training loss and perplexity\n","%%capture\n","!python run_language_modeling_w_loss.py \\\n","    --output_dir=output_Dehao_wd_1e1_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=output_Dehao_wd_1e1_line \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/train.txt \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --overwrite_output_dir \\\n","    --line_by_line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9rlgg86Xb0k","colab_type":"code","colab":{}},"source":["# perplexity on dev set\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=output_Dehao_wd_1e1_line \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/dev.txt \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --overwrite_output_dir \\\n","    --line_by_line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T60mrmHsXp9u","colab_type":"code","colab":{}},"source":["# perplexity on test set\n","%%capture\n","!python run_language_modeling.py \\\n","    --output_dir=output_Dehao_wd_1e1_line \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=output_Dehao_wd_1e1_line \\\n","    --do_eval \\\n","    --eval_data_file=./data/generation/test.txt \\\n","    --train_data_file=./data/generation/train.txt \\\n","    --overwrite_output_dir \\\n","    --line_by_line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZO7n42EJtNEh","colab_type":"code","outputId":"9cc1290f-376c-4b76-ae3b-dfa88fa32d75","executionInfo":{"status":"ok","timestamp":1587311536477,"user_tz":240,"elapsed":136365,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["inputs = ['My','The','One','When','If','Our','First','Natural','We','Because']\n","cmds = [\"\"\"\n","python run_generation.py \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=output_Dehao_wd_1e1_line \\\n","    --prompt {} \\\n","    --length 32 \\\n","    --repetition_penalty 1.2 \\\n","    --seed 9001\n","\"\"\".format(i) for i in inputs]\n","\n","for cmd in cmds:\n","  !{cmd}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-19 15:50:00.258365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:50:01 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:50:02 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:50:03 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:50:03 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:50:03 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:50:27 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='My', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","My movie tells the story of an old captain, and his last days as a general of the indian army during world war i. he begins a long struggle for survival\n","2020-04-19 15:50:30.569971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:50:32 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:50:32 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:50:32 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:50:32 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:50:32 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:50:39 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='The', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","The film opens with a limousine driver, jay, with his friend and potential mate, riding in it. jay agrees to a simple plan of the day and throws himself\n","2020-04-19 15:50:42.553026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:50:44 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:50:44 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:50:44 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:50:44 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:50:44 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:50:51 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='One', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","One child has been able to learn a wonderful thing, but he can do no more than act like it does not matter. it is part of the cycle of agony\n","2020-04-19 15:50:53.822512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:50:55 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:50:55 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:50:55 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:50:55 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:50:55 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:51:02 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='When', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","When she comes out, wearing a long pink dress, an old man sees her and falls in love with her. <unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n","2020-04-19 15:51:05.200449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:51:06 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:51:06 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:51:06 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:51:06 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:51:06 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:51:14 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='If', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","If his bet is a winner, the cowboy and the ranch hand then decide to find out what kind of rancher roy'mcewan might be. after spending years\n","2020-04-19 15:51:16.629524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:51:18 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:51:18 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:51:18 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:51:18 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:51:18 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:51:25 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='Our', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","Our princess starts out the cat and mouse game, that everyone on the planet is looking for. some people accidentally bump into. at this point, i guess some guy\n","2020-04-19 15:51:28.203876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:51:29 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:51:29 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:51:29 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:51:29 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:51:29 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:51:37 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='First', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","First grown from the quadriplegic youth, alrel and his team of friends stop at the birth canal station, a nearby field called \" the express lane \"\n","2020-04-19 15:51:40.262545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:51:41 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:51:41 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:51:41 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:51:41 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:51:41 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:51:49 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='Natural', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","Natural french gardener mr. neville has a slip, and without the money he had been promised the previous year by colonel sieine, well, the pipe mr neville\n","2020-04-19 15:51:51.719970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:51:53 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:51:53 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:51:53 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:51:53 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:51:53 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:52:00 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='We', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","We go out of the garden and to the house. we are seen taking up their bows, filling them up with water. they then shoot, and kill someone who\n","2020-04-19 15:52:04.224601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 15:52:05 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 15:52:05 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 15:52:05 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 15:52:05 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 15:52:05 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 15:52:13 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='Because', repetition_penalty=1.2, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","Because of his luck, anthony delantan, a popular and intense writer, has taken to becoming an astronaut after the 70s. already, he has gained influence\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FC629LHHK35O","colab_type":"code","outputId":"ac366f7a-0d44-44a4-b92a-5b551c89481a","executionInfo":{"status":"ok","timestamp":1587312129419,"user_tz":240,"elapsed":12060,"user":{"displayName":"Dehao Zhang","photoUrl":"","userId":"00427090514518802898"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_generation.py \\\n","    --model_type=openai-gpt \\\n","    --model_name_or_path=output_Dehao_wd_1e1_line \\\n","    --prompt 'When' \\\n","    --length 32 \\\n","    --repetition_penalty 1.5 \\\n","    --seed 9001"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-19 16:01:57.029376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   Model name 'output_Dehao_wd_1e1_line' not found in model shortcut name list (openai-gpt). Assuming 'output_Dehao_wd_1e1_line' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   Didn't find file output_Dehao_wd_1e1_line/added_tokens.json. We won't load it.\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/vocab.json\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/merges.txt\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   loading file None\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/special_tokens_map.json\n","04/19/2020 16:01:58 - INFO - transformers.tokenization_utils -   loading file output_Dehao_wd_1e1_line/tokenizer_config.json\n","04/19/2020 16:01:58 - WARNING - transformers.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","04/19/2020 16:01:58 - INFO - transformers.configuration_utils -   loading configuration file output_Dehao_wd_1e1_line/config.json\n","04/19/2020 16:01:58 - INFO - transformers.configuration_utils -   Model config OpenAIGPTConfig {\n","  \"_num_labels\": 2,\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"min_length\": 0,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","04/19/2020 16:01:58 - INFO - transformers.modeling_utils -   loading weights file output_Dehao_wd_1e1_line/pytorch_model.bin\n","04/19/2020 16:02:05 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=32, model_name_or_path='output_Dehao_wd_1e1_line', model_type='openai-gpt', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='When', repetition_penalty=1.5, seed=9001, stop_token=None, temperature=1.0, xlm_language='')\n","=== GENERATED SEQUENCE 1 ===\n","When she comes out, aisha's life is changed forever. from the first day of school to cheerleading lessons, ajay is devastated. he believes that time\n"],"name":"stdout"}]}]}