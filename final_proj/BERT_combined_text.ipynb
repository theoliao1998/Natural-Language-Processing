{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_combined_text",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4eed880ba1248baa5482b9845ca5699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05d3f04da7b4406a9b56f01b28add971",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_597bb4b9c99240908fd4d9c636ad0173",
              "IPY_MODEL_4ecc4829356248dbadac0a1d7494d3de"
            ]
          }
        },
        "05d3f04da7b4406a9b56f01b28add971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "597bb4b9c99240908fd4d9c636ad0173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2a2d1ad734bf4af38c8cd51788d1ee0a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_528ce6b902614f0092443430b4055abb"
          }
        },
        "4ecc4829356248dbadac0a1d7494d3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bab220448f854f9aaa9ec64387c9b202",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 831kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e68da05bbf3244ba9640dc01f2f5a3b5"
          }
        },
        "2a2d1ad734bf4af38c8cd51788d1ee0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "528ce6b902614f0092443430b4055abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bab220448f854f9aaa9ec64387c9b202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e68da05bbf3244ba9640dc01f2f5a3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7f5a0189f3d416a9cc361f4ef53982f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c75a3dddb9fa42cb97eaf568e0ef3912",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a86817e02004441834ff19bf49124c3",
              "IPY_MODEL_c67f8d80e3f5456b8d8f1d5c1ffd83a8"
            ]
          }
        },
        "c75a3dddb9fa42cb97eaf568e0ef3912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a86817e02004441834ff19bf49124c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74d4f33433d14082969831829d804eec",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_569245ee9a484076b9860c02d9765545"
          }
        },
        "c67f8d80e3f5456b8d8f1d5c1ffd83a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1876392cea8435690891c727955c946",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 336B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_968c2be03cc2483bb44ad376168663e1"
          }
        },
        "74d4f33433d14082969831829d804eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "569245ee9a484076b9860c02d9765545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1876392cea8435690891c727955c946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "968c2be03cc2483bb44ad376168663e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5c5104d55da45759e9c481424ecbd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eecc6a105fb84fbda5ad138dad8ec155",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_735f8b79bc2e48bcb94ad00f6cb587b2",
              "IPY_MODEL_89bf9fab2c5345448bc6ea5453c38f0a"
            ]
          }
        },
        "eecc6a105fb84fbda5ad138dad8ec155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "735f8b79bc2e48bcb94ad00f6cb587b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1bb1d120fa8d45e595e1e3d7b8208a3c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45807b98bbb94a51858c449ea5da7a8a"
          }
        },
        "89bf9fab2c5345448bc6ea5453c38f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50da2e8504154398adf70abd6ce1ff07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:05&lt;00:00, 6.69MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee37fdee8dab4b27b513b125950dde68"
          }
        },
        "1bb1d120fa8d45e595e1e3d7b8208a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45807b98bbb94a51858c449ea5da7a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50da2e8504154398adf70abd6ce1ff07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee37fdee8dab4b27b513b125950dde68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZPiBU6PgggV",
        "colab_type": "code",
        "outputId": "05397e82-37d5-4ffc-d70f-de7d1cbaebba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 4.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=f7f5a6a592ae79d63db67432bf0315006da35d76b891189d062dc442eeb7c0d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjgeXKrLgyKD",
        "colab_type": "code",
        "outputId": "cd268a73-d307-4f2d-b251-7b7c3365082b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VDx7LpehHDo",
        "colab_type": "code",
        "outputId": "06425fdd-b063-4b58-f174-07acef699c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/630final"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/630final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTnryWEWc7T",
        "colab_type": "code",
        "outputId": "724617a0-29f1-47ed-ab14-f02785c2e50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('./data/train.csv')\n",
        "val_df = pd.read_csv('./data/dev.csv')\n",
        "test_df = pd.read_csv('./data/test.csv')\n",
        "\n",
        "val_df\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted...</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ...</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>1202</td>\n",
              "      <td>Supreme &lt;Court/&gt; Once Again Strikes Down Racia...</td>\n",
              "      <td>leaders</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>14764</td>\n",
              "      <td>Trump Mocks Schumer â€™s Tears ; Vows to â€˜ Make ...</td>\n",
              "      <td>Insane</td>\n",
              "      <td>33333</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>12595</td>\n",
              "      <td>US government memo on the &lt;danger/&gt; of leaking...</td>\n",
              "      <td>amusement</td>\n",
              "      <td>22111</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>70</td>\n",
              "      <td>Newt Gingrich : Join Me in Supporting Judge Ro...</td>\n",
              "      <td>Molest</td>\n",
              "      <td>32110</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>14315</td>\n",
              "      <td>In Search of Donald Trump at His Boyhood &lt;Home/&gt;</td>\n",
              "      <td>Castle</td>\n",
              "      <td>11100</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0      1723  ...       1.0\n",
              "1     12736  ...       0.8\n",
              "2     12274  ...       0.6\n",
              "3      8823  ...       1.6\n",
              "4      5087  ...       0.4\n",
              "...     ...  ...       ...\n",
              "2414   1202  ...       0.2\n",
              "2415  14764  ...       3.0\n",
              "2416  12595  ...       1.4\n",
              "2417     70  ...       1.4\n",
              "2418  14315  ...       0.6\n",
              "\n",
              "[2419 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JXSJq-Jtbi3",
        "colab_type": "code",
        "outputId": "536432c4-5d0b-4422-b09c-64e62b01e30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import base64\n",
        "import io\n",
        "%matplotlib inline\n",
        "sns.set() \n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgvoDW3Zu5Xn",
        "colab_type": "code",
        "outputId": "6b5068ee-cf8d-4a2b-92cf-11068ad02a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.append(train_df['meanGrade'],val_df['meanGrade'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2, 1.6, 1. , ..., 1.4, 1.4, 0.6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHWybpARtnDX",
        "colab_type": "code",
        "outputId": "14b0ad69-38c2-4234-e543-111212f7c567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "\n",
        "ax.set_title(\"Count of Mean Grades\", fontsize=16)\n",
        "ax.set_xlabel(\"Mean Grades\")\n",
        "sns.distplot(np.append(train_df['meanGrade'],val_df['meanGrade']),bins=6,ax=ax,kde=False);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnhhp-2Y6nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "val_df['text'] = val_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "test_df['text'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKYI8UP2bPlM",
        "colab_type": "code",
        "outputId": "7a66060e-c3c9-4ec2-91f2-dcd910550e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df['old'] = train_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "val_df['old'] = val_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "test_df['old'] = test_df.apply(lambda x:x['original'][x['original'].find('<')+1:x['original'].find('>')-1],axis=1)\n",
        "\n",
        "train_df['text2'] = train_df.apply(lambda x:x['text'] + ' [SEP] From '+x['old'] + ' to '+x['edit'] ,axis=1)\n",
        "val_df['text2'] = val_df.apply(lambda x:x['text'] + ' [SEP] From '+x['old'] + ' to '+x['edit'] ,axis=1)\n",
        "test_df['text2'] = test_df.apply(lambda x:x['text'] + ' [SEP] From '+x['old'] + ' to '+x['edit'] ,axis=1)\n",
        "\n",
        "test_df['text2'][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Latest : Election tally shows Cars turning right [SEP] From Austria to Cars'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2DeXF8hU9j",
        "colab_type": "code",
        "outputId": "06faab47-2dfd-41ba-88f5-441d32212e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMJjC-9ZhkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkkgrgjIN5Yh",
        "colab_type": "code",
        "outputId": "45677c2e-d13e-47d2-ba7b-3e2edbd7ed8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = train_df['text2'].values\n",
        "labels = train_df['meanGrade'].values\n",
        "labels[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2, 1.6, 1. , 0.4, 0. , 1.2, 1.2, 1. , 0.2, 0. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "memh29ygRFYO",
        "colab_type": "code",
        "outputId": "3558450d-83db-47dd-a3e6-846278ce5573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "f4eed880ba1248baa5482b9845ca5699",
            "05d3f04da7b4406a9b56f01b28add971",
            "597bb4b9c99240908fd4d9c636ad0173",
            "4ecc4829356248dbadac0a1d7494d3de",
            "2a2d1ad734bf4af38c8cd51788d1ee0a",
            "528ce6b902614f0092443430b4055abb",
            "bab220448f854f9aaa9ec64387c9b202",
            "e68da05bbf3244ba9640dc01f2f5a3b5"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4eed880ba1248baa5482b9845ca5699",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meg0oVYQwHW9",
        "colab_type": "code",
        "outputId": "197c711d-29f4-4f3c-bf1c-69f3357d23fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "labels[:10]\n",
        "sentences"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq [SEP] From Isis to twins',\n",
              "       'Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ? [SEP] From Syria to bowling',\n",
              "       'Iceland PM Calls Snap Vote as Pedophile Furor Crashes party  [SEP] From Coalition to party',\n",
              "       ...,\n",
              "       \"Cruise line Carnival Corp. joins the fight against Bermuda 's same-sex raisin ban [SEP] From marriage to raisin\",\n",
              "       'Columbia police hunt woman seen with cake near University of Missouri campus [SEP] From gun to cake',\n",
              "       \"Here 's What 's In The House-Approved Health food Bill [SEP] From Care to food\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_FvjCfvW7V_",
        "colab_type": "code",
        "outputId": "5b2c8cdc-0b45-4d16-9039-939f089cb782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq [SEP] From Isis to twins\n",
            "Token IDs: tensor([  101,  2605,  2003,  1520,  5933,  2091,  2049,  4480,  2040,  2587,\n",
            "         8178,  1521,  2302,  3979,  1999,  5712,   102,  2013, 18301,  2000,\n",
            "         8178,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLBUUWdFyjeJ",
        "colab_type": "code",
        "outputId": "27c364d6-f8f8-4d2b-96d3-6df89f0532d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "test_df.head(10)\n",
        "val_df.head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>text</th>\n",
              "      <th>old</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted...</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted ...</td>\n",
              "      <td>men</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Special chef appointed to Trump Russia</td>\n",
              "      <td>prosecutor</td>\n",
              "      <td>Special chef appointed to Trump Russia [SEP] F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "      <td>suspects</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ...</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unf...</td>\n",
              "      <td>reprimands</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "      <td>Missile</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13178</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murph...</td>\n",
              "      <td>chase</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murph...</td>\n",
              "      <td>replace</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11799</td>\n",
              "      <td>Trump â€™s next military &lt;scapegoat/&gt; : Foreign-...</td>\n",
              "      <td>assassinations</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Trump â€™s next military assassinations : Foreig...</td>\n",
              "      <td>scapegoat</td>\n",
              "      <td>Trump â€™s next military assassinations : Foreig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13425</td>\n",
              "      <td>President Trump â€™s Golden Age of &lt;Trolling/&gt;</td>\n",
              "      <td>Skydiving</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>President Trump â€™s Golden Age of Skydiving</td>\n",
              "      <td>Trolling</td>\n",
              "      <td>President Trump â€™s Golden Age of Skydiving  [S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12497</td>\n",
              "      <td>US urges UN to &lt;punish/&gt; Iran , but Russia say...</td>\n",
              "      <td>tickle</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says n...</td>\n",
              "      <td>punish</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1185</td>\n",
              "      <td>Taliban &lt;kill/&gt; 95 with ambulance bomb</td>\n",
              "      <td>bores</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb</td>\n",
              "      <td>kill</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb [SEP] Fro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                              text2\n",
              "0   1723  ...  Thousands of gay and bisexual swans convicted ...\n",
              "1  12736  ...  Special chef appointed to Trump Russia [SEP] F...\n",
              "2  12274  ...  Spanish police detain man and search Ripoll ad...\n",
              "3   8823  ...  N.Y. Times applauds reporter for sharing ' unf...\n",
              "4   5087  ...  Vladimir Putin Releases Video Simulation Of Ru...\n",
              "5  13178  ...  Ex-Goldman Sachs boss , Obama ambassador Murph...\n",
              "6  11799  ...  Trump â€™s next military assassinations : Foreig...\n",
              "7  13425  ...  President Trump â€™s Golden Age of Skydiving  [S...\n",
              "8  12497  ...  US urges UN to tickle Iran , but Russia says n...\n",
              "9   1185  ...  Taliban bores 95 with ambulance bomb [SEP] Fro...\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID91LxeszFke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-processing for validation set\n",
        "sentences_val = val_df['text2'].values\n",
        "labels_val = val_df['meanGrade'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nfxw095y5nN",
        "colab_type": "code",
        "outputId": "f5be03a7-ef2a-4512-fb78-c784dea7a7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences_val:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "labels_val = torch.tensor(labels_val)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_val[0])\n",
        "print('Token IDs:', input_ids_val[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned [SEP] From men to swans\n",
            "Token IDs: tensor([  101,  5190,  1997,  5637,  1998, 22437, 26699,  7979,  1997,  2146,\n",
            "         1011,  8961,  4424, 18421,  2024, 12770, 14933,  2098,   102,  2013,\n",
            "         2273,  2000, 26699,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-t1ixw4MmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28u4yx0Dr2Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32fvlVG7o5D",
        "colab_type": "code",
        "outputId": "1041f7d9-503a-404c-f47c-5bfd9f6bf2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a7f5a0189f3d416a9cc361f4ef53982f",
            "c75a3dddb9fa42cb97eaf568e0ef3912",
            "7a86817e02004441834ff19bf49124c3",
            "c67f8d80e3f5456b8d8f1d5c1ffd83a8",
            "74d4f33433d14082969831829d804eec",
            "569245ee9a484076b9860c02d9765545",
            "a1876392cea8435690891c727955c946",
            "968c2be03cc2483bb44ad376168663e1",
            "d5c5104d55da45759e9c481424ecbd12",
            "eecc6a105fb84fbda5ad138dad8ec155",
            "735f8b79bc2e48bcb94ad00f6cb587b2",
            "89bf9fab2c5345448bc6ea5453c38f0a",
            "1bb1d120fa8d45e595e1e3d7b8208a3c",
            "45807b98bbb94a51858c449ea5da7a8a",
            "50da2e8504154398adf70abd6ce1ff07",
            "ee37fdee8dab4b27b513b125950dde68"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 1, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7f5a0189f3d416a9cc361f4ef53982f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5c5104d55da45759e9c481424ecbd12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLgvsjVb-JWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm5wdKt_w6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91bMBN5BKrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc0Dqm55AnLN",
        "colab_type": "code",
        "outputId": "bf5a2bd4-1aae-4346-fb45-6a836582f875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = model.double()\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # # ========================================\n",
        "    # #               Training\n",
        "    # # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        " \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        y_pred = np.append(y_pred,logits)\n",
        "        y_true = np.append(y_true,label_ids)\n",
        "        \n",
        "\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    print(\"  RMSE: {0:.4f}\".format(rmse))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. RMSE.': rmse,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:32.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:53.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5302\n",
            "  Validation Loss: 0.28\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5419\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5418\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5600\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:34 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfRbvN0mKk46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}