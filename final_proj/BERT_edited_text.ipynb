{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_edited_text",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94b4df51e531429eb5b9b194604558f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ec7367cbd694e2f89ae9ff4412c3a95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_249762d798ec414a97166ebe21cd79a4",
              "IPY_MODEL_a37a6d296f9e4305a0935fa285042c97"
            ]
          }
        },
        "9ec7367cbd694e2f89ae9ff4412c3a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "249762d798ec414a97166ebe21cd79a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2cdc793eede463ab27ed6cc527f2bf4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_051b820a97f04cddb07e33bc5eb83947"
          }
        },
        "a37a6d296f9e4305a0935fa285042c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55bcadfe86a34a9d9186f8188ed64d8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 308kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_044ed4a2c8154fbfb73446c039d7d9eb"
          }
        },
        "d2cdc793eede463ab27ed6cc527f2bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "051b820a97f04cddb07e33bc5eb83947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55bcadfe86a34a9d9186f8188ed64d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "044ed4a2c8154fbfb73446c039d7d9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2bec6a0e5e746b48506cd8dd2b114d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81624bb040d947669623bae0b05aec04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b5165fb247648f9b74e6b5c3ebd59ff",
              "IPY_MODEL_e553f94fdedd4e2db528a65ffccd527c"
            ]
          }
        },
        "81624bb040d947669623bae0b05aec04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b5165fb247648f9b74e6b5c3ebd59ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f54bc320a124689be3387e5d10f0ec0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f83813955474de39b4d696f6710cd7f"
          }
        },
        "e553f94fdedd4e2db528a65ffccd527c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d174edaabe94cc9921ae66ce9942fd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 12.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_786d1a708bf842e9a80e6279249c548b"
          }
        },
        "8f54bc320a124689be3387e5d10f0ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f83813955474de39b4d696f6710cd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d174edaabe94cc9921ae66ce9942fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "786d1a708bf842e9a80e6279249c548b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0639f9a1a724d449700ef8572a3db71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09f5389bd9334a62944b4363f058edca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0efb2eea96c14c9eb6cc05fe3c95b5f4",
              "IPY_MODEL_6a038f4662474b02bb7fafa21dd66a74"
            ]
          }
        },
        "09f5389bd9334a62944b4363f058edca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0efb2eea96c14c9eb6cc05fe3c95b5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fa6264577ce4677b7633037a745378b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9268ee3d385e483c943f3d15a3fbb580"
          }
        },
        "6a038f4662474b02bb7fafa21dd66a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1044622648bf477d9bade3751e8b3e11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:38&lt;00:00, 11.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a1407a49b4a4abfb99675a20bae984e"
          }
        },
        "7fa6264577ce4677b7633037a745378b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9268ee3d385e483c943f3d15a3fbb580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1044622648bf477d9bade3751e8b3e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a1407a49b4a4abfb99675a20bae984e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZPiBU6PgggV",
        "colab_type": "code",
        "outputId": "bdd2d224-d30a-4a5e-892b-f4d2c57b4b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 2.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=f85c96674ed98ce99883887dd046ef3f13aaa4a33695f95775d85e0abe82d328\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjgeXKrLgyKD",
        "colab_type": "code",
        "outputId": "a464f63c-f789-4290-c9a5-5b1ecead34c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VDx7LpehHDo",
        "colab_type": "code",
        "outputId": "536a6f2a-dc49-4dbe-a28a-598bf66920e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/630final"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/630final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTnryWEWc7T",
        "colab_type": "code",
        "outputId": "ab8b9b70-0edb-42fb-8d0f-457eb8166f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('./data/train.csv')\n",
        "val_df = pd.read_csv('./data/dev.csv')\n",
        "test_df = pd.read_csv('./data/test.csv')\n",
        "\n",
        "len(val_df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2419"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JXSJq-Jtbi3",
        "colab_type": "code",
        "outputId": "18b743f4-890c-483d-9c10-0f76e0f37e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import base64\n",
        "import io\n",
        "%matplotlib inline\n",
        "sns.set() \n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgvoDW3Zu5Xn",
        "colab_type": "code",
        "outputId": "310c3360-1326-48ba-a080-2cb532d07cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.append(train_df['meanGrade'],val_df['meanGrade'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2, 1.6, 1. , ..., 1.4, 1.4, 0.6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHWybpARtnDX",
        "colab_type": "code",
        "outputId": "ddf9e15c-c771-4280-ea7c-e1b5b4486e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "\n",
        "ax.set_title(\"Count of Mean Grades\", fontsize=16)\n",
        "ax.set_xlabel(\"Mean Grades\")\n",
        "sns.distplot(np.append(train_df['meanGrade'],val_df['meanGrade']),bins=6,ax=ax,kde=False);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKnhhp-2Y6nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "val_df['text'] = val_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "test_df['text'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW9H2tqrUzFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text'] = train_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "val_df['text'] = val_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)\n",
        "test_df['text'] = test_df.apply(lambda x:x['original'].replace(x['original'][x['original'].find('<'):x['original'].find('>')+1],x['edit']) ,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKYI8UP2bPlM",
        "colab_type": "code",
        "outputId": "e904d91c-5a7e-4c3b-cc81-68d95bed03c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "test_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>The Latest : Election tally shows &lt;Austria/&gt; t...</td>\n",
              "      <td>Cars</td>\n",
              "      <td>The Latest : Election tally shows Cars turning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2157</td>\n",
              "      <td>House Intel &lt;Republicans/&gt; Have Cleared Trump ...</td>\n",
              "      <td>onions</td>\n",
              "      <td>House Intel onions Have Cleared Trump . So Are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9385</td>\n",
              "      <td>Christmas Is Canceled : Nazareth ’s Muslim &lt;Ma...</td>\n",
              "      <td>grump</td>\n",
              "      <td>Christmas Is Canceled : Nazareth ’s Muslim gru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14434</td>\n",
              "      <td>White House says Trump 's legal &lt;team/&gt; suppor...</td>\n",
              "      <td>bozos</td>\n",
              "      <td>White House says Trump 's legal bozos supports...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9462</td>\n",
              "      <td>Election &lt;analysts/&gt; move Ryan seat toward Dem...</td>\n",
              "      <td>movers</td>\n",
              "      <td>Election movers move Ryan seat toward Dems aft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3019</th>\n",
              "      <td>3921</td>\n",
              "      <td>Sen. Bernie Sanders says he ’s “ sickened ” by...</td>\n",
              "      <td>mucus</td>\n",
              "      <td>Sen. Bernie Sanders says he ’s “ sickened ” by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3020</th>\n",
              "      <td>12371</td>\n",
              "      <td>Trump Repeals Regulation Protecting &lt;Workers/&gt;...</td>\n",
              "      <td>Owners</td>\n",
              "      <td>Trump Repeals Regulation Protecting Owners Fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>6845</td>\n",
              "      <td>Spicer : We do n't regret repeating claim that...</td>\n",
              "      <td>licked</td>\n",
              "      <td>Spicer : We do n't regret repeating claim that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3022</th>\n",
              "      <td>2902</td>\n",
              "      <td>Gunshots Fired Outside Houses of &lt;Parliament/&gt;...</td>\n",
              "      <td>dogs</td>\n",
              "      <td>Gunshots Fired Outside Houses of dogs in London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>4440</td>\n",
              "      <td>Flynn has promised Special Counsel ' full &lt;coo...</td>\n",
              "      <td>monty</td>\n",
              "      <td>Flynn has promised Special Counsel ' full mont...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3024 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                               text\n",
              "0        36  ...  The Latest : Election tally shows Cars turning...\n",
              "1      2157  ...  House Intel onions Have Cleared Trump . So Are...\n",
              "2      9385  ...  Christmas Is Canceled : Nazareth ’s Muslim gru...\n",
              "3     14434  ...  White House says Trump 's legal bozos supports...\n",
              "4      9462  ...  Election movers move Ryan seat toward Dems aft...\n",
              "...     ...  ...                                                ...\n",
              "3019   3921  ...  Sen. Bernie Sanders says he ’s “ sickened ” by...\n",
              "3020  12371  ...  Trump Repeals Regulation Protecting Owners Fro...\n",
              "3021   6845  ...  Spicer : We do n't regret repeating claim that...\n",
              "3022   2902  ...    Gunshots Fired Outside Houses of dogs in London\n",
              "3023   4440  ...  Flynn has promised Special Counsel ' full mont...\n",
              "\n",
              "[3024 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2DeXF8hU9j",
        "colab_type": "code",
        "outputId": "d560b5aa-5c23-4803-c8ad-900721593842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhuBkS4Njfxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #1 fine tune with distilbert model\n",
        "# !python run_language_modeling.py \\\n",
        "#     --output_dir=output_Theo_cls_5e_6_new \\\n",
        "#     --model_type=distilbert-base-cased \\\n",
        "#     --model_name_or_path=distilbert-base-cased \\\n",
        "#     --do_train \\\n",
        "#     --mlm \\\n",
        "#     --train_data_file=./data/generation/train.txt \\\n",
        "#     --line_by_line \\\n",
        "#     --eval_all_checkpoints \\\n",
        "#     --do_eval \\\n",
        "#     --eval_data_file=./data/generation/dev.txt \\\n",
        "#     --save_steps 2000 \\\n",
        "#     --learning_rate 5e-6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMJjC-9ZhkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkkgrgjIN5Yh",
        "colab_type": "code",
        "outputId": "1c11a274-a1b9-487f-dea3-bcdd8422d528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = train_df['text'].values\n",
        "labels = train_df['meanGrade'].values\n",
        "labels[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2, 1.6, 1. , 0.4, 0. , 1.2, 1.2, 1. , 0.2, 0. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "memh29ygRFYO",
        "colab_type": "code",
        "outputId": "0af06ccb-6f4f-4bef-c140-a754b6fc50b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "94b4df51e531429eb5b9b194604558f4",
            "9ec7367cbd694e2f89ae9ff4412c3a95",
            "249762d798ec414a97166ebe21cd79a4",
            "a37a6d296f9e4305a0935fa285042c97",
            "d2cdc793eede463ab27ed6cc527f2bf4",
            "051b820a97f04cddb07e33bc5eb83947",
            "55bcadfe86a34a9d9186f8188ed64d8a",
            "044ed4a2c8154fbfb73446c039d7d9eb"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94b4df51e531429eb5b9b194604558f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meg0oVYQwHW9",
        "colab_type": "code",
        "outputId": "ad3e5fb7-d269-47ed-e1c8-b986163ae71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "labels[:10]\n",
        "sentences"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq',\n",
              "       'Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ?',\n",
              "       'Iceland PM Calls Snap Vote as Pedophile Furor Crashes party ',\n",
              "       ...,\n",
              "       \"Cruise line Carnival Corp. joins the fight against Bermuda 's same-sex raisin ban\",\n",
              "       'Columbia police hunt woman seen with cake near University of Missouri campus',\n",
              "       \"Here 's What 's In The House-Approved Health food Bill\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_FvjCfvW7V_",
        "colab_type": "code",
        "outputId": "eea1867c-3701-4008-d77f-05c3e4cc7fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels).double()\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq\n",
            "Token IDs: tensor([ 101, 2605, 2003, 1520, 5933, 2091, 2049, 4480, 2040, 2587, 8178, 1521,\n",
            "        2302, 3979, 1999, 5712,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLBUUWdFyjeJ",
        "colab_type": "code",
        "outputId": "d10bff79-ca1e-487f-98f6-3c3fbdb2b211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "test_df.head(10)\n",
        "val_df.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted...</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Special chef appointed to Trump Russia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Spanish police detain man and search Ripoll ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ...</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Ru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13178</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murph...</td>\n",
              "      <td>chase</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11799</td>\n",
              "      <td>Trump ’s next military &lt;scapegoat/&gt; : Foreign-...</td>\n",
              "      <td>assassinations</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Trump ’s next military assassinations : Foreig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13425</td>\n",
              "      <td>President Trump ’s Golden Age of &lt;Trolling/&gt;</td>\n",
              "      <td>Skydiving</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>President Trump ’s Golden Age of Skydiving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12497</td>\n",
              "      <td>US urges UN to &lt;punish/&gt; Iran , but Russia say...</td>\n",
              "      <td>tickle</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1185</td>\n",
              "      <td>Taliban &lt;kill/&gt; 95 with ambulance bomb</td>\n",
              "      <td>bores</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                               text\n",
              "0   1723  ...  Thousands of gay and bisexual swans convicted ...\n",
              "1  12736  ...             Special chef appointed to Trump Russia\n",
              "2  12274  ...  Spanish police detain man and search Ripoll ad...\n",
              "3   8823  ...  N.Y. Times applauds reporter for sharing ' unf...\n",
              "4   5087  ...  Vladimir Putin Releases Video Simulation Of Ru...\n",
              "5  13178  ...  Ex-Goldman Sachs boss , Obama ambassador Murph...\n",
              "6  11799  ...  Trump ’s next military assassinations : Foreig...\n",
              "7  13425  ...        President Trump ’s Golden Age of Skydiving \n",
              "8  12497  ...  US urges UN to tickle Iran , but Russia says n...\n",
              "9   1185  ...               Taliban bores 95 with ambulance bomb\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID91LxeszFke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-processing for validation set\n",
        "sentences_val = val_df['text'].values\n",
        "labels_val = val_df['meanGrade'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nfxw095y5nN",
        "colab_type": "code",
        "outputId": "8f4542d7-2135-42e7-cfb0-1e84815b3467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences_val:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "labels_val = torch.tensor(labels_val)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_val[0])\n",
        "print('Token IDs:', input_ids_val[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned\n",
            "Token IDs: tensor([  101,  5190,  1997,  5637,  1998, 22437, 26699,  7979,  1997,  2146,\n",
            "         1011,  8961,  4424, 18421,  2024, 12770, 14933,  2098,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-t1ixw4MmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28u4yx0Dr2Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32fvlVG7o5D",
        "colab_type": "code",
        "outputId": "b01dd9b0-3a89-42c1-e2e3-8afb42983bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c2bec6a0e5e746b48506cd8dd2b114d6",
            "81624bb040d947669623bae0b05aec04",
            "9b5165fb247648f9b74e6b5c3ebd59ff",
            "e553f94fdedd4e2db528a65ffccd527c",
            "8f54bc320a124689be3387e5d10f0ec0",
            "7f83813955474de39b4d696f6710cd7f",
            "6d174edaabe94cc9921ae66ce9942fd7",
            "786d1a708bf842e9a80e6279249c548b",
            "b0639f9a1a724d449700ef8572a3db71",
            "09f5389bd9334a62944b4363f058edca",
            "0efb2eea96c14c9eb6cc05fe3c95b5f4",
            "6a038f4662474b02bb7fafa21dd66a74",
            "7fa6264577ce4677b7633037a745378b",
            "9268ee3d385e483c943f3d15a3fbb580",
            "1044622648bf477d9bade3751e8b3e11",
            "9a1407a49b4a4abfb99675a20bae984e"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 1, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2bec6a0e5e746b48506cd8dd2b114d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0639f9a1a724d449700ef8572a3db71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLgvsjVb-JWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqm5wdKt_w6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91bMBN5BKrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc0Dqm55AnLN",
        "colab_type": "code",
        "outputId": "f4d1820c-a1e8-4869-8031-0804d5ece89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = model.double()\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # # ========================================\n",
        "    # #               Training\n",
        "    # # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        " \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        y_pred = np.append(y_pred,logits)\n",
        "        y_true = np.append(y_true,label_ids)\n",
        "        \n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    print(\"  RMSE: {0:.4f}\".format(rmse))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. RMSE.': rmse,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:32.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:53.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5348\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:32.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:53.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5483\n",
            "  Validation Loss: 0.30\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:32.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:53.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5364\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    302.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    302.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    302.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    302.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    302.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    302.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    302.    Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.5582\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:35 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfRbvN0mKk46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}